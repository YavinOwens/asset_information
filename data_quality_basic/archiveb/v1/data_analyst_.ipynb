{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'age': [25, 30, None, 22, 28],\n",
    "    'gender': ['F', 'M', 'M', 'M', 'F'],\n",
    "    'email': ['alice@example.com', 'bob@example.com', 'charlie@example', 'david@example.com', 'eve@example.com']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# File details\n",
    "file_name = 'example_data.csv'\n",
    "file_path = os.path.abspath(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality issues logged in 'data_quality.log'.\n"
     ]
    }
   ],
   "source": [
    "# # Data quality check functions\n",
    "# def check_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"Check for missing values in the DataFrame.\"\"\"\n",
    "#     logging.debug(\"Checking for missing values.\")\n",
    "#     missing_values = df.isnull().sum()\n",
    "#     return missing_values[missing_values > 0]\n",
    "\n",
    "# def check_duplicates(df: pd.DataFrame) -> int:\n",
    "#     \"\"\"Check for duplicate rows in the DataFrame.\"\"\"\n",
    "#     logging.debug(\"Checking for duplicate rows.\")\n",
    "#     return df.duplicated().sum()\n",
    "\n",
    "# def check_inconsistencies(df: pd.DataFrame, column: str, valid_values: list) -> pd.Series:\n",
    "#     \"\"\"Check for inconsistencies in a specific column.\"\"\"\n",
    "#     logging.debug(f\"Checking for inconsistencies in column '{column}'.\")\n",
    "#     return df[~df[column].isin(valid_values)][column]\n",
    "\n",
    "# # Logging configuration\n",
    "# logging.basicConfig(filename='data_quality.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def log_data_quality_issue(level: str, file_name: str, file_path: str, column_name: str, issue: str):\n",
    "#     \"\"\"Log a data quality issue.\"\"\"\n",
    "#     message = f\"File: {file_name}, Path: {file_path}, Column: {column_name}, Issue: {issue}\"\n",
    "#     if level == 'DEBUG':\n",
    "#         logging.debug(message)\n",
    "#     elif level == 'INFO':\n",
    "#         logging.info(message)\n",
    "#     elif level == 'WARNING':\n",
    "#         logging.warning(message)\n",
    "#     elif level == 'ERROR':\n",
    "#         logging.error(message)\n",
    "\n",
    "# def report_data_quality_issues(df: pd.DataFrame, file_name: str, file_path: str):\n",
    "#     \"\"\"Generate a report of data quality issues.\"\"\"\n",
    "#     logging.info(\"Starting data quality checks.\")\n",
    "    \n",
    "#     try:\n",
    "#         missing_values = check_missing_values(df)\n",
    "#         if not missing_values.empty:\n",
    "#             for column, count in missing_values.items():\n",
    "#                 log_data_quality_issue('INFO', file_name, file_path, column, f\"Missing Values: {count}\")\n",
    "#         else:\n",
    "#             log_data_quality_issue('DEBUG', file_name, file_path, 'All Columns', \"No missing values found.\")\n",
    "#     except Exception as e:\n",
    "#         log_data_quality_issue('ERROR', file_name, file_path, 'All Columns', f\"Error checking missing values: {e}\")\n",
    "    \n",
    "#     try:\n",
    "#         duplicates = check_duplicates(df)\n",
    "#         if duplicates > 0:\n",
    "#             log_data_quality_issue('INFO', file_name, file_path, 'All Columns', f\"Duplicate Rows: {duplicates}\")\n",
    "#         else:\n",
    "#             log_data_quality_issue('DEBUG', file_name, file_path, 'All Columns', \"No duplicate rows found.\")\n",
    "#     except Exception as e:\n",
    "#         log_data_quality_issue('ERROR', file_name, file_path, 'All Columns', f\"Error checking duplicates: {e}\")\n",
    "    \n",
    "#     try:\n",
    "#         gender_inconsistencies = check_inconsistencies(df, 'gender', ['M', 'F'])\n",
    "#         if not gender_inconsistencies.empty:\n",
    "#             for inconsistency in gender_inconsistencies.unique():\n",
    "#                 count = (gender_inconsistencies == inconsistency).sum()\n",
    "#                 log_data_quality_issue('WARNING', file_name, file_path, 'gender', f\"Inconsistent Value: {inconsistency} (Count: {count})\")\n",
    "#         else:\n",
    "#             log_data_quality_issue('DEBUG', file_name, file_path, 'gender', \"No gender inconsistencies found.\")\n",
    "#     except Exception as e:\n",
    "#         log_data_quality_issue('ERROR', file_name, file_path, 'gender', f\"Error checking gender inconsistencies: {e}\")\n",
    "    \n",
    "#     logging.info(\"Data quality checks completed.\")\n",
    "\n",
    "# # Report data quality issues\n",
    "# report_data_quality_issues(df, file_name, file_path)\n",
    "\n",
    "# print(f\"Data quality issues logged in 'data_quality.log'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality issues logged in 'data_quality.log'.\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import logging\n",
    "# import os\n",
    "\n",
    "# # Example data\n",
    "# data = {\n",
    "#     'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "#     'age': [25, 30, None, 22, 28],\n",
    "#     'gender': ['F', 'M', 'M', 'M', 'F'],\n",
    "#     'email': ['alice@example.com', 'bob@example.com', 'charlie@example', 'david@example.com', 'eve@example.com']\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # File details\n",
    "# file_name = 'example_data.csv'\n",
    "# file_path = os.path.abspath(file_name)\n",
    "\n",
    "# # Data quality check functions\n",
    "# def check_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     \"\"\"Check for missing values in the DataFrame.\"\"\"\n",
    "#     logging.debug(\"Checking for missing values.\")\n",
    "#     missing_values = df.isnull().sum()\n",
    "#     return missing_values[missing_values > 0]\n",
    "\n",
    "# def check_duplicates(df: pd.DataFrame) -> int:\n",
    "#     \"\"\"Check for duplicate rows in the DataFrame.\"\"\"\n",
    "#     logging.debug(\"Checking for duplicate rows.\")\n",
    "#     return df.duplicated().sum()\n",
    "\n",
    "# def check_inconsistencies(df: pd.DataFrame, column: str, valid_values: list) -> pd.Series:\n",
    "#     \"\"\"Check for inconsistencies in a specific column.\"\"\"\n",
    "#     logging.debug(f\"Checking for inconsistencies in column '{column}'.\")\n",
    "#     return df[~df[column].isin(valid_values)][column]\n",
    "\n",
    "# # Logging configuration\n",
    "# logging.basicConfig(filename='data_quality.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# def log_data_quality_issue(level: str, file_name: str, file_path: str, column_name: str, issue: str):\n",
    "#     \"\"\"Log a data quality issue.\"\"\"\n",
    "#     message = f\"File: {file_name}, Path: {file_path}, Column: {column_name}, Issue: {issue}\"\n",
    "#     if level == 'DEBUG':\n",
    "#         logging.debug(message)\n",
    "#     elif level == 'INFO':\n",
    "#         logging.info(message)\n",
    "#     elif level == 'WARNING':\n",
    "#         logging.warning(message)\n",
    "#     elif level == 'ERROR':\n",
    "#         logging.error(message)\n",
    "\n",
    "# def report_data_quality_issues(df: pd.DataFrame, file_name: str, file_path: str):\n",
    "#     \"\"\"Generate a report of data quality issues.\"\"\"\n",
    "#     logging.info(\"Starting data quality checks.\")\n",
    "    \n",
    "#     try:\n",
    "#         missing_values = check_missing_values(df)\n",
    "#         total_records = len(df)\n",
    "#         if not missing_values.empty:\n",
    "#             for column, count in missing_values.items():\n",
    "#                 passed = total_records - count\n",
    "#                 log_data_quality_issue('INFO', file_name, file_path, column, f\"Missing Values: {count} (Passed: {passed}, Failed: {count})\")\n",
    "#         else:\n",
    "#             log_data_quality_issue('INFO', file_name, file_path, 'All Columns', f\"No missing values found. (Passed: {total_records}, Failed: 0)\")\n",
    "#     except Exception as e:\n",
    "#         log_data_quality_issue('ERROR', file_name, file_path, 'All Columns', f\"Error checking missing values: {e}\")\n",
    "    \n",
    "#     try:\n",
    "#         duplicates = check_duplicates(df)\n",
    "#         if duplicates > 0:\n",
    "#             passed = total_records - duplicates\n",
    "#             log_data_quality_issue('INFO', file_name, file_path, 'All Columns', f\"Duplicate Rows: {duplicates} (Passed: {passed}, Failed: {duplicates})\")\n",
    "#         else:\n",
    "#             log_data_quality_issue('INFO', file_name, file_path, 'All Columns', f\"No duplicate rows found. (Passed: {total_records}, Failed: 0)\")\n",
    "#     except Exception as e:\n",
    "#         log_data_quality_issue('ERROR', file_name, file_path, 'All Columns', f\"Error checking duplicates: {e}\")\n",
    "    \n",
    "#     try:\n",
    "#         gender_inconsistencies = check_inconsistencies(df, 'gender', ['M', 'F'])\n",
    "#         if not gender_inconsistencies.empty:\n",
    "#             for inconsistency in gender_inconsistencies.unique():\n",
    "#                 count = (gender_inconsistencies == inconsistency).sum()\n",
    "#                 passed = total_records - count\n",
    "#                 log_data_quality_issue('WARNING', file_name, file_path, 'gender', f\"Inconsistent Value: {inconsistency} (Passed: {passed}, Failed: {count})\")\n",
    "#         else:\n",
    "#             log_data_quality_issue('INFO', file_name, file_path, 'gender', f\"No gender inconsistencies found. (Passed: {total_records}, Failed: 0)\")\n",
    "#     except Exception as e:\n",
    "#         log_data_quality_issue('ERROR', file_name, file_path, 'gender', f\"Error checking gender inconsistencies: {e}\")\n",
    "    \n",
    "#     logging.info(\"Data quality checks completed.\")\n",
    "\n",
    "# # Report data quality issues\n",
    "# report_data_quality_issues(df, file_name, file_path)\n",
    "\n",
    "# print(f\"Data quality issues logged in 'data_quality.log'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality issues logged in 'data_quality.log'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Example data\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'age': [25, 30, None, 22, 28],\n",
    "    'gender': ['F', 'M', 'M', 'M', 'F'],\n",
    "    'email': ['alice@example.com', 'bob@example.com', 'charlie@example', 'david@example.com', 'eve@example.com']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# File details\n",
    "file_name = 'example_data.csv'\n",
    "file_path = os.path.abspath(file_name)\n",
    "\n",
    "# Data quality check functions\n",
    "def check_missing_values(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Check for missing values in the DataFrame.\"\"\"\n",
    "    logging.debug(\"Checking for missing values.\")\n",
    "    return df.isnull().sum()\n",
    "\n",
    "def get_missing_value_indices(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Get indices of missing values for each column.\"\"\"\n",
    "    missing_value_indices = {}\n",
    "    for column in df.columns:\n",
    "        missing_indices = df[df[column].isnull()].index.tolist()\n",
    "        if missing_indices:\n",
    "            missing_value_indices[column] = missing_indices\n",
    "    return missing_value_indices\n",
    "\n",
    "def check_duplicates(df: pd.DataFrame) -> int:\n",
    "    \"\"\"Check for duplicate rows in the DataFrame.\"\"\"\n",
    "    logging.debug(\"Checking for duplicate rows.\")\n",
    "    return df.duplicated().sum()\n",
    "\n",
    "def get_duplicate_indices(df: pd.DataFrame) -> list:\n",
    "    \"\"\"Get indices of duplicate rows.\"\"\"\n",
    "    return df[df.duplicated()].index.tolist()\n",
    "\n",
    "def check_inconsistencies(df: pd.DataFrame, column: str, valid_values: list) -> pd.Series:\n",
    "    \"\"\"Check for inconsistencies in a specific column.\"\"\"\n",
    "    logging.debug(f\"Checking for inconsistencies in column '{column}'.\")\n",
    "    return df[~df[column].isin(valid_values)][column]\n",
    "\n",
    "def get_inconsistency_indices(df: pd.DataFrame, column: str, valid_values: list) -> list:\n",
    "    \"\"\"Get indices of inconsistent values in a specific column.\"\"\"\n",
    "    return df[~df[column].isin(valid_values)].index.tolist()\n",
    "\n",
    "# Logging configuration\n",
    "logging.basicConfig(filename='data_quality.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def log_data_quality_issue(level: str, file_name: str, file_path: str, column_name: str, issue: str, indices: list):\n",
    "    \"\"\"Log a data quality issue.\"\"\"\n",
    "    indices_str = \", \".join(map(str, indices))\n",
    "    message = f\"File: {file_name}, Path: {file_path}, Column: {column_name}, Issue: {issue}, Indices: {indices_str}\"\n",
    "    if level == 'DEBUG':\n",
    "        logging.debug(message)\n",
    "    elif level == 'INFO':\n",
    "        logging.info(message)\n",
    "    elif level == 'WARNING':\n",
    "        logging.warning(message)\n",
    "    elif level == 'ERROR':\n",
    "        logging.error(message)\n",
    "\n",
    "def report_data_quality_issues(df: pd.DataFrame, file_name: str, file_path: str):\n",
    "    \"\"\"Generate a report of data quality issues.\"\"\"\n",
    "    logging.info(\"Starting data quality checks.\")\n",
    "    \n",
    "    total_records = len(df)\n",
    "    \n",
    "    try:\n",
    "        missing_values = check_missing_values(df)\n",
    "        missing_value_indices = get_missing_value_indices(df)\n",
    "        for column, count in missing_values.items():\n",
    "            if count > 0:\n",
    "                passed = total_records - count\n",
    "                indices = missing_value_indices[column]\n",
    "                log_data_quality_issue('INFO', file_name, file_path, column, f\"Missing Values: {count} (Passed: {passed}, Failed: {count})\", indices)\n",
    "            else:\n",
    "                log_data_quality_issue('INFO', file_name, file_path, column, f\"No missing values found. (Passed: {total_records}, Failed: 0)\", [])\n",
    "    except Exception as e:\n",
    "        log_data_quality_issue('ERROR', file_name, file_path, 'All Columns', f\"Error checking missing values: {e}\", [])\n",
    "    \n",
    "    try:\n",
    "        duplicates = check_duplicates(df)\n",
    "        duplicate_indices = get_duplicate_indices(df)\n",
    "        if duplicates > 0:\n",
    "            passed = total_records - duplicates\n",
    "            log_data_quality_issue('INFO', file_name, file_path, 'All Columns', f\"Duplicate Rows: {duplicates} (Passed: {passed}, Failed: {duplicates})\", duplicate_indices)\n",
    "        else:\n",
    "            log_data_quality_issue('INFO', file_name, file_path, 'All Columns', f\"No duplicate rows found. (Passed: {total_records}, Failed: 0)\", [])\n",
    "    except Exception as e:\n",
    "        log_data_quality_issue('ERROR', file_name, file_path, 'All Columns', f\"Error checking duplicates: {e}\", [])\n",
    "    \n",
    "    try:\n",
    "        gender_inconsistencies = check_inconsistencies(df, 'gender', ['M', 'F'])\n",
    "        inconsistency_indices = get_inconsistency_indices(df, 'gender', ['M', 'F'])\n",
    "        if not gender_inconsistencies.empty:\n",
    "            for inconsistency in gender_inconsistencies.unique():\n",
    "                count = (gender_inconsistencies == inconsistency).sum()\n",
    "                passed = total_records - count\n",
    "                indices = inconsistency_indices\n",
    "                log_data_quality_issue('WARNING', file_name, file_path, 'gender', f\"Inconsistent Value: {inconsistency} (Passed: {passed}, Failed: {count})\", indices)\n",
    "        else:\n",
    "            log_data_quality_issue('INFO', file_name, file_path, 'gender', f\"No gender inconsistencies found. (Passed: {total_records}, Failed: 0)\", [])\n",
    "    except Exception as e:\n",
    "        log_data_quality_issue('ERROR', file_name, file_path, 'gender', f\"Error checking gender inconsistencies: {e}\", [])\n",
    "    \n",
    "    logging.info(\"Data quality checks completed.\")\n",
    "\n",
    "# Report data quality issues\n",
    "report_data_quality_issues(df, file_name, file_path)\n",
    "\n",
    "print(f\"Data quality issues logged in 'data_quality.log'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doing a thing to allow user to visualise the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_log_line(line):\n",
    "    \"\"\"Parse a single line of the log file and return a dictionary with the extracted information.\"\"\"\n",
    "    log_pattern = re.compile(\n",
    "        r'(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3}) - '\n",
    "        r'(?P<level>\\w+) - '\n",
    "        r'File: (?P<file>.*?), Path: (?P<path>.*?), Column: (?P<column>.*?), '\n",
    "        r'Issue: (?P<issue>.*?), Indices: (?P<indices>.*)'\n",
    "    )\n",
    "    match = log_pattern.match(line)\n",
    "    if match:\n",
    "        return match.groupdict()\n",
    "    return None\n",
    "\n",
    "def read_log_file(log_file_path):\n",
    "    \"\"\"Read the log file and extract the relevant information.\"\"\"\n",
    "    log_entries = []\n",
    "    with open(log_file_path, 'r') as log_file:\n",
    "        for line in log_file:\n",
    "            log_entry = parse_log_line(line)\n",
    "            if log_entry:\n",
    "                log_entries.append(log_entry)\n",
    "    return log_entries\n",
    "\n",
    "def write_csv_file(log_entries, csv_file_path):\n",
    "    \"\"\"Write the extracted log information to a CSV file.\"\"\"\n",
    "    keys = log_entries[0].keys() if log_entries else []\n",
    "    with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "        dict_writer = csv.DictWriter(csv_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(log_entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created at data_quality_issues.csv\n"
     ]
    }
   ],
   "source": [
    "log_file_path = 'data_quality.log'\n",
    "csv_file_path = 'data_quality_issues.csv'\n",
    "\n",
    "log_entries = read_log_file(log_file_path)\n",
    "write_csv_file(log_entries, csv_file_path)\n",
    "print(f\"CSV file created at {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
